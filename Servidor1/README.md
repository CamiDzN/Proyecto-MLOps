# Servicios en Servidor1

Este README describe en detalle c贸mo est谩n organizados y desplegados los servicios en **Servidor1** dentro del proyecto `PROYECTO-MLOPS`.

##  Descripci贸n General del Servidor 1

El **Servidor 1** es el componente encargado de la **ingesta, preprocesamiento y preparaci贸n de datos** para el modelo de predicci贸n de precios de propiedades. Su funci贸n principal es automatizar el flujo de trabajo de datos utilizando **Apache Airflow**.

### 锔 Componentes Clave

- **Apache Airflow**: Orquesta el DAG (`Directed Acyclic Graph`) definido en <mcfile name="realtor_price_model.py" path="c:\Users\luisc\OneDrive\Documents\GitHub\Proyecto-MLOps\Servidor1\dags\realtor_price_model.py"></mcfile>, que gestiona todo el ciclo de vida del preprocesamiento de datos y el entrenamiento del modelo.
- **MySQL**: Base de datos utilizada para almacenar los datos crudos (`realtor_raw`) y los datos preprocesados (`train_clean`, `validation_clean`, `test_clean`).

###  Flujo de Trabajo del DAG (`realtor_price_model.py`)

El DAG <mcsymbol name="realtor_price_model" filename="realtor_price_model.py" path="c:\Users\luisc\OneDrive\Documents\GitHub\Proyecto-MLOps\Servidor1\dags\realtor_price_model.py" startline="30" type="function"></mcsymbol> automatiza los siguientes pasos:

1.  **Extracci贸n de Datos (`extract_data`)**: Se conecta a una API externa para obtener nuevos registros de propiedades. Los datos se insertan en la tabla `realtor_raw` en MySQL. Este paso tambi茅n verifica si se ha recolectado toda la informaci贸n m铆nima necesaria.
2.  **Decisi贸n de Entrenamiento (`decide_train`)**: Un operador de ramificaci贸n que decide si se debe proceder con el entrenamiento del modelo. Las condiciones para entrenar incluyen:
    -   Si no hay nuevos registros, el DAG finaliza sin entrenar.
    -   Si se cumplen ciertas validaciones sobre las caracter铆sticas de los datos.
    -   Si el n煤mero de nuevos registros supera un umbral (ej. 10000), se procede al entrenamiento.
    -   Registra m茅tricas y etiquetas en MLflow sobre la decisi贸n tomada.
3.  **Reinicio de Datos (`reset_data`)**: Si se ha recolectado toda la informaci贸n m铆nima necesaria, este paso reinicia la generaci贸n de datos en la API externa y trunca las tablas relevantes en las bases de datos `RawData` y `CleanData` para preparar un nuevo ciclo de entrenamiento.
4.  **Divisi贸n de Datos (`split_data`)**: Divide los datos crudos en conjuntos de entrenamiento, validaci贸n y prueba, almacen谩ndolos en tablas separadas en MySQL.
5.  **Limpieza de Datos (`clean_data`)**: Realiza el preprocesamiento de los datos, incluyendo la eliminaci贸n de valores at铆picos, el manejo de valores nulos y la transformaci贸n de caracter铆sticas. Los datos limpios se almacenan en tablas dedicadas (`train_clean`, `validation_clean`, `test_clean`).
6.  **Entrenamiento del Modelo (`train_model`)**: Entrena un modelo de regresi贸n lineal (o Ridge Regression con GridSearchCV para optimizaci贸n de hiperpar谩metros) utilizando los datos limpios. Registra el modelo, las m茅tricas (RMSE) y los par谩metros en **MLflow**.
7.  **Evaluaci贸n del Modelo (`evaluate_model`)**: Eval煤a el modelo entrenado utilizando el conjunto de prueba y registra las m茅tricas finales en MLflow.
8.  **Registro del Modelo (`register_model`)**: Registra el modelo en el **MLflow Model Registry**, gestionando las versiones y las etapas del ciclo de vida del modelo (Staging, Production, Archived).

###  Despliegue y Ejecuci贸n

El despliegue de los servicios en Servidor 1 se realiza a trav茅s de **Docker Compose** para Airflow y **Kubernetes** para la base de datos MySQL. Los manifiestos de Kubernetes para MySQL se encuentran en la carpeta `kubernetes/`.

Para ejecutar el DAG, aseg煤rate de que Airflow est茅 configurado y que las conexiones a las bases de datos MySQL (`AIRFLOW_CONN_MYSQL_DEFAULT` y `AIRFLOW_CONN_MYSQL_CLEAN`) est茅n definidas correctamente en el entorno de Airflow.
