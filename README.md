#  Descripci贸n General del Proyecto

Este proyecto implementa una soluci贸n completa de MLOps distribuida en tres servidores, dise帽ada para gestionar todo el ciclo de vida de un modelo de machine learning.

La arquitectura del proyecto est谩 basada en contenedores Docker orquestados con Kubernetes (MicroK8s) y est谩 organizada en tres entornos funcionales independientes, desplegados en m谩quinas virtuales diferentes:

- **Servidor 1**: Encargado del preprocesamiento autom谩tico de datos con Apache Airflow.
- **Servidor 2**: Responsable del registro de experimentos y gesti贸n de artefactos con MLflow y MinIO.
- **Servidor 3**: Despliega el modelo en producci贸n mediante una API con FastAPI, integra monitoreo con Prometheus & Grafana y una interfaz de usuario con Streamlit.

Este enfoque modular permite escalar y mantener cada componente de forma independiente, emulando un entorno real de producci贸n distribuido.