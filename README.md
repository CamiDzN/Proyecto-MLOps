
# ğŸ§  DescripciÃ³n General del Proyecto

Este proyecto implementa una soluciÃ³n completa de MLOps distribuida en tres servidores, diseÃ±ada para gestionar todo el ciclo de vida de un modelo de machine learning que predice precios de propiedades inmobiliarias.

La arquitectura del proyecto estÃ¡ basada en contenedores Docker orquestados con Kubernetes (MicroK8s) y estÃ¡ organizada en tres entornos funcionales independientes, desplegados en mÃ¡quinas virtuales diferentes:

- **Servidor 1**: Encargado del preprocesamiento automÃ¡tico de datos con Apache Airflow.
- **Servidor 2**: Responsable del registro de experimentos y gestiÃ³n de artefactos con MLflow y MinIO.
- **Servidor 3**: Despliega el modelo en producciÃ³n mediante una API con FastAPI, integra monitoreo con Prometheus & Grafana, pruebas de carga con Locust y una interfaz de usuario con Streamlit.

Este enfoque modular permite escalar y mantener cada componente de forma independiente, emulando un entorno real de producciÃ³n distribuido.

> ğŸ’¡ El objetivo principal es proporcionar predicciones precisas de precios inmobiliarios mediante un sistema MLOps completo, permitiendo a los usuarios obtener estimaciones basadas en caracterÃ­sticas de las propiedades.

---

## ğŸ—‚ï¸ DistribuciÃ³n del Proyecto por Servidores

Este proyecto fue desarrollado colaborativamente y distribuido en tres mÃ¡quinas virtuales, cada una encargada de un componente clave del flujo de trabajo MLOps. Cada servidor tiene su propio `README.md` con detalles tÃ©cnicos y operativos especÃ­ficos:

| Servidor | Rol Principal                                   | Enlace al Detalle |
|----------|--------------------------------------------------|-------------------|
| ğŸŸ¦ Servidor 1 | Preprocesamiento de datos con Airflow           | [Ver README Servidor 1](./Servidor1/README.md) |
| ğŸŸ© Servidor 2 | Seguimiento de experimentos con MLflow y MinIO  | [Ver README Servidor 2](./Servidor2/README.md) |
| ğŸŸ¥ Servidor 3 | Despliegue, monitoreo y pruebas de inferencia   | [Ver README Servidor 3](./Servidor3/README.md) |

Cada una de estas secciones incluye:
- Los contenedores desplegados.
- Los DAGs y notebooks asociados.
- Instrucciones de uso y pruebas.

> ğŸ“Œ **Nota:** Todos los servidores estÃ¡n conectados en red local y comparten el acceso a la base de datos y el almacenamiento distribuido configurado para simular un entorno de producciÃ³n real.

---

## ğŸ§± Arquitectura General del Proyecto

El proyecto estÃ¡ distribuido en **tres servidores (mÃ¡quinas virtuales)** que trabajan de manera coordinada para implementar un pipeline completo de MLOps. Cada servidor aloja componentes especÃ­ficos de la arquitectura, asegurando modularidad, escalabilidad y claridad en la implementaciÃ³n.

A continuaciÃ³n se presenta el diagrama de la arquitectura general:

![Arquitectura](public/1. General.png)

### ğŸ”¹ Servidor 1 â€“ Preprocesamiento y Almacenamiento de Datos
- **Airflow**: OrquestaciÃ³n de pipelines de preprocesamiento y entrenamiento.
- **Base de Datos MySQL**: Almacena datos en dos capas:
  - `RawData`: Datos crudos separados en train, validation y test.
  - `CleanData`: Datos preprocesados listos para entrenamiento.
- **DAGs**:
  - `realtor_price_model.py`: Preprocesamiento, entrenamiento y registro del modelo de precios inmobiliarios.

### ğŸ”¸ Servidor 2 â€“ Seguimiento de Experimentos
- **MLflow Tracking Server**: Registro de mÃ©tricas, parÃ¡metros y artefactos.
- **MinIO**: Almacenamiento compatible con S3 para guardar artefactos de modelos.
- **MySQL Metadata**: Almacena la metadata generada por MLflow.
- Imagen personalizada de MLflow desplegada con dependencias para conectividad segura.

### ğŸ”º Servidor 3 â€“ Despliegue, Observabilidad y Experiencia de Usuario
- **FastAPI**: API de inferencia conectada al modelo en producciÃ³n desde MLflow.
- **Streamlit**: Interfaz grÃ¡fica para realizar predicciones desde la web.
- **Prometheus + Grafana**: Monitoreo del comportamiento de la API:
  - Latencia, uso de memoria, conteo de inferencias.

> ğŸ§© Cada componente se desplegÃ³ como contenedor independiente y se conectÃ³ a travÃ©s de redes virtuales internas. Las IPs asignadas por el clÃºster a cada servidor aseguran el enrutamiento correcto entre servicios.

---
## ğŸ› ï¸ TecnologÃ­as y Componentes Utilizados

El proyecto se compone de varios microservicios, cada uno desplegado en contenedores independientes, comunicados entre sÃ­ dentro de un entorno orquestado con Kubernetes:

- **MLflow**: GestiÃ³n de experimentos y modelos. Conectado a MinIO (artefactos) y MySQL (metadatos).
- **Airflow**: OrquestaciÃ³n de pipelines de preprocesamiento y entrenamiento.
- **MinIO**: Almacenamiento local de artefactos, compatible con S3.
- **MySQL**: Bases de datos para RawData, CleanData y metadata de MLflow y Airflow.

- **FastAPI**: API de inferencia del modelo en producciÃ³n.
- **Streamlit**: Interfaz grÃ¡fica para predicciones del modelo.
- **Prometheus + Grafana**: Observabilidad y monitoreo de mÃ©tricas de inferencia.


## ğŸš€ Â¿CÃ³mo ejecutar el proyecto completo?
âœ… AsegÃºrate de que los 3 servidores estÃ©n activos, conectados en la misma red y con Kubernetes (MicroK8s) habilitado.

ğŸ”Œ Paso a paso por servidor
ğŸ–¥ï¸ Servidor 1 â€” Preprocesamiento y orquestaciÃ³n

```bash
kubectl apply -f Servidor1/kubernetes/
```
Accede a Airflow y ejecuta el DAG realtor_price_model.py.

ğŸ—ƒï¸ Servidor 2 â€” Almacenamiento y MLflow

```bash
docker build -t custom-mlflow:latest .
docker tag custom-mlflow:latest localhost:32000/custom-mlflow:latest
docker push localhost:32000/custom-mlflow:latest
kubectl apply -f Servidor2/kubernetes/
kubectl apply -f Servidor2/kubernetes/create-minio-bucket.yaml
```

ğŸ“¡ Servidor 3 â€” Inferencia, monitoreo y UI

```bash
kubectl apply -f Servidor3/kubernetes/
```

Accede a la API o interfaz de Streamlit para hacer predicciones.
Verifica mÃ©tricas en Prometheus y visualÃ­zalas en Grafana.
